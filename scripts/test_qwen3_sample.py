#!/usr/bin/env python3
"""
Script: test_qwen3_sample.py
- Loads a model 
- Finds a sample from the hierarchical dataset structure (split/game_id/*.jsonl).
- Generates a response and extracts the JSON output.
"""

import argparse
import json
import os
import sys
import re
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

def log(*args, **kwargs):
    """Print to stderr for logging/debugging."""
    print(*args, file=sys.stderr, **kwargs)

def find_matching_sample(dataset_dir):
    """
    Recursively search for the first valid .jsonl file in the dataset directory.
    The new structure is: dataset_dir / split / game_id / instance_id.jsonl
    Each file contains exactly one sample on the first line.
    """
    log(f"[INFO] Scanning directory: {dataset_dir}")
    
    for root, dirs, files in os.walk(dataset_dir):
        for f in files:
            if f.endswith('.jsonl'):
                fp = os.path.join(root, f)
                try:
                    with open(fp, 'r', encoding='utf-8') as fh:
                        # In the new build_dataset.py, each file has 1 line = 1 sample
                        line = fh.readline()
                        if not line.strip():
                            continue
                        
                        ep = json.loads(line)
                        
                        # Validation: Check if it has the essential keys generated by build_dataset.py
                        if 'prompt' in ep and 'answer' in ep:
                            return ep, fp
                except Exception as e:
                    log(f"[WARNING] Error reading {fp}: {e}")
                    continue
                    
    return None, None

def extract_after_think(generated_text):
    """Remove Chain-of-Thought parts (<think>...</think>) if present."""
    idx = generated_text.rfind('</think>')
    if idx != -1:
        return generated_text[idx+len('</think>'):].strip()
    return generated_text.strip()

def try_parse_json(text):
    """
    Robustly extract and parse a JSON object from text using Regex.
    """
    # 1. Try to find markdown code block: ```json ... ```
    match = re.search(r"```json\s*(\{.*?\})\s*```", text, re.DOTALL)
    if match:
        try: return json.loads(match.group(1))
        except: pass

    # 2. Try to find the outermost curly braces { ... }
    match = re.search(r"(\{.*\})", text, re.DOTALL)
    if match:
        try: return json.loads(match.group(1))
        except: pass
            
    # 3. Fallback: Try parsing the whole text
    try: return json.loads(text)
    except: pass

    return None

def main():
    parser = argparse.ArgumentParser()
    # 사용자 환경에 맞는 모델명으로 기본값 변경
    parser.add_argument('--model-name', default='Qwen/Qwen3-8B', help='Model name on HF') 
    parser.add_argument('--cache-dir', default=None, help='Hugging Face local cache dir')
    # 기본 경로를 새로 생성된 hybrid_ours 폴더로 설정
    parser.add_argument('--dataset-dir', default='dataset_experiments/hybrid_ours/train', help='Root directory to search for .jsonl files')
    parser.add_argument('--max-tokens', type=int, default=1024)
    parser.add_argument('--device', default='cuda', help='device override, eg cuda or cpu')
    parser.add_argument('--sample-file', default=None, help='Path to a specific jsonl file to test (optional)')
    
    args = parser.parse_args()

    # 1. Find Sample
    log('[INFO] Searching dataset for a matching sample...')
    sample, fp = None, None
    
    if args.sample_file:
        if not os.path.isfile(args.sample_file):
            log(f'[ERROR] File not found: {args.sample_file}')
            sys.exit(1)
        fp = args.sample_file
        with open(fp, 'r', encoding='utf-8') as fh:
            line = fh.readline()
            if line:
                sample = json.loads(line)
    else:
        sample, fp = find_matching_sample(args.dataset_dir)

    if not sample:
        log(f'[ERROR] No valid sample found in {args.dataset_dir}')
        sys.exit(1)

    log(f'[INFO] Using sample from: {fp}')
    log(f'[INFO] Game ID: {sample.get("game_id")}, Instance ID: {sample.get("instance_id")}')
    
    prompt = sample.get('prompt', '')
    
    # 2. Load Model
    if args.device:
        device = torch.device(args.device)
    else:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    log(f'[INFO] Loading model {args.model_name} on {device}...')

    try:
        tokenizer = AutoTokenizer.from_pretrained(args.model_name, cache_dir=args.cache_dir, trust_remote_code=True)
        model = AutoModelForCausalLM.from_pretrained(
            args.model_name, 
            cache_dir=args.cache_dir, 
            torch_dtype=torch.float16 if device.type == 'cuda' else torch.float32, 
            trust_remote_code=True,
            device_map='auto' if torch.cuda.is_available() else None
        )
        # device_map='auto'가 아닐 경우 수동 할당
        if not hasattr(model, 'hf_device_map') and not getattr(model, 'is_loaded_in_8bit', False):
            model.to(device)
    except Exception as e:
        log(f'[ERROR] Failed to load model: {e}')
        sys.exit(1)

    # 3. Generate
    # Chat Template 적용이 필요할 수 있으나, 현재 Prompt가 이미 완성형(Instruction 포함)이므로 Raw Input으로 넣음
    # 만약 모델이 Chat 형식을 강제한다면 tokenizer.apply_chat_template를 써야 함.
    # 여기서는 Text Completion 방식으로 진행.
    
    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)
    
    log('[INFO] Generating response...')
    with torch.no_grad():
        outputs = model.generate(
            **inputs, 
            max_new_tokens=args.max_tokens, 
            do_sample=True, 
            temperature=0.6,
            top_p=0.9,
            pad_token_id=tokenizer.eos_token_id
        )
    
    # 입력 프롬프트 길이를 제외하고 생성된 부분만 디코딩
    input_len = inputs.input_ids.shape[1]
    generated_ids = outputs[0][input_len:]
    full_response = tokenizer.decode(generated_ids, skip_special_tokens=True)
    
    # 4. Extract & Parse
    content_to_parse = extract_after_think(full_response)
    
    log('--- [Model Output] ---')
    log(content_to_parse)
    log('----------------------')

    parsed_json = try_parse_json(content_to_parse)

    if parsed_json:
        print(json.dumps(parsed_json, indent=2))
        
        # 정답과 비교 (Optional)
        gt = sample.get("answer", {})
        log(f'\n[Compare] Ground Truth Action: {gt.get("actions", [{}])[0].get("tool_name")}')
        
        sys.exit(0)
    else:
        log('[ERROR] Failed to parse JSON from response.')
        sys.exit(1)

if __name__ == '__main__':
    main()